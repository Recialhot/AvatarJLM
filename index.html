<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling">
  <meta name="keywords" content="3D reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/virtual-reality.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://pengfeiren96.github.io/DIR/">
            Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image
          </a>
          <a class="navbar-item" href="https://zxz267.github.io/HaMuCo/">
            HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-widescreen">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=3hSD41oAAAAJ">Xiaozheng Zheng</a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=iaqDkqMAAAAJ">Zhuo Su</a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=v8TFZI4AAAAJ">Chao Wen</a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?&user=ECKq3aUAAAAJ">Zhou Xue</a>,
            </span>
            
            <span class="author-block">
              <a href="https://scholar.google.com/citations?&user=OEZ816YAAAAJ">Xiaojie Jin</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ByteDance</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
             <span class="link-block">
               <a href="https://arxiv.org/pdf/2308.08855.pdf"
                  class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                     <i class="fas fa-file-pdf"></i>
                 </span>
                 <span>Paper</span>
               </a>
             </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2308.08855"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zxz267/AvatarJLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-widescreen">
    <div class="hero-body">
      <div class="is-centered">
      <img src="./static/images/teaser-1.png" width="1000px"/>
      </div>
      <h2 class="subtitle has-text-centered">
        Overview of our framework. <br>
        Our method accurately estimates full-body motion using only head and hand tracking signals.
      </h2>

    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/1-1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/1-2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/2-1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/2-2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/3-1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/3-2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/3-3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/3-4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/4-1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/4-2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/4-3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/4-4.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            To bridge the physical and virtual worlds for rapidly developed VR/AR applications, the ability to realistically drive 3D full-body avatars is of great significance. 
            Although real-time body tracking with only the head-mounted displays (HMDs) and hand controllers is heavily under-constrained, a carefully designed end-to-end neural network is of great potential to solve the problem by learning from large-scale motion data.
            To this end, we propose a two-stage framework that can obtain accurate and smooth full-body motions with the three tracking signals of head and hands only. 
            Our framework explicitly models the joint-level features in the first stage and utilizes them as spatiotemporal tokens for alternating spatial and temporal transformer blocks to capture joint-level correlations in the second stage. 
            Furthermore, we design a set of loss terms to constrain the task of a high degree of freedom, such that we can exploit the potential of our joint-level modeling. 
            With extensive experiments on the AMASS motion dataset and real-captured data, we validate the effectiveness of our designs and show our proposed method can achieve more accurate and smooth motion compared to existing approaches.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
<!--    <div class="columns is-centered has-text-centered">-->
<!--      <div class="column is-four-fifths">-->
<!--        <h2 class="title is-3">Video</h2>-->
<!--        <div class="publication-video">-->
<!--          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"-->
<!--                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Network Architecture</h2>

        <!-- Interpolating. -->
<!--        <div class="content has-text-justified">-->
<!--          <p>-->
<!--            We can also animate the scene by interpolating the deformation latent codes of two input-->
<!--            frames. Use the slider here to linearly interpolate between the left frame and the right-->
<!--            frame.-->
<!--          </p>-->
<!--        </div>-->
        <div class="columns is-vcentered interpolation-panel">
            <img src="./static/images/JLM-framework.png"
                 class="interpolation-image"
                 alt="Network Architecture."/>
          </div>
        </div>
        <br/>
      </div>
    </div>
    <!--/ Animation. -->
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <h3 class="title is-4">Ours vs. AvatarPoser</h3>
        <div class="columns is-vcentered interpolation-panel">
          <img src="./static/images/JLM_and_AP.jpg"
               class="interpolation-image"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Different Features</h2>
          <p>
            Ablation study for our method with four different generated features, in which the errors are color-coded in red.
          </p>
          <img src="./static/images/ablation_initial_feature.jpg"
               class="interpolation-image"/>
        </div>
      </div>
      <div class="column">
        <h2 class="title is-3">Losses</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Ablation study for our method with different loss settings, in which the errors are color-coded in red.
            </p>
            <img src="./static/images/ablation_loss.jpg"
               class="interpolation-image"/>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{zheng2023realistic,
      title={Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling},
      author={Zheng, Xiaozheng and Su, Zhuo and Wen, Chao and Xue, Zhou and Jin, Xiaojie},
      booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
      year={2023}}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2308.08855.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://zxz267.github.io/AvatarJLM" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
          <a href="https://www.flaticon.com/free-icons/vr-glasses" title="vr glasses icons">Vr glasses icons created by Freepik - Flaticon</a>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
